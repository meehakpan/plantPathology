{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Generator\n",
    "from model import Discriminator\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from data_loader import get_loader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "data_dir = '/ssd_local/hpml/pytorch/celeba/'\n",
    "celeba_loader = get_loader(data_dir + 'images', data_dir + 'list_attr_celeba.txt', selected_attrs,\n",
    "                                   178, 128, 16,\n",
    "                                   'CelebA', 'test', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "    \"\"\"Solver for training and testing StarGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, celeba_loader):\n",
    "        \"\"\"Initialize configurations.\"\"\"\n",
    "\n",
    "        # Data loader.\n",
    "        self.celeba_loader = celeba_loader\n",
    "        \n",
    "        # Model configurations.\n",
    "        self.c_dim = 5\n",
    "        self.c2_dim = 8\n",
    "        self.image_size = 128\n",
    "        self.g_conv_dim = 64\n",
    "        self.d_conv_dim = 64\n",
    "        self.g_repeat_num = 6\n",
    "        self.d_repeat_num = 6\n",
    "        self.lambda_cls = 1\n",
    "        self.lambda_rec = 10\n",
    "        self.lambda_gp = 10\n",
    "        self.selected_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "        \n",
    "        # Test configurations.\n",
    "        self.test_iters = 200000\n",
    "\n",
    "        # Miscellaneous.\n",
    "        self.device = torch.device('cuda')\n",
    "        \n",
    "        \n",
    "        # Directories.\n",
    "        self.log_dir = 'stargan/logs'\n",
    "        self.sample_dir = 'stargan/samples'\n",
    "        self.model_save_dir = 'stargan_celeba_128/models'\n",
    "        self.result_dir = 'stargan_celeba_128/results'\n",
    "\n",
    "        # Build the model and tensorboard.\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Create a generator and a discriminator.\"\"\"\n",
    "        self.G = Generator(self.g_conv_dim, self.c_dim, self.g_repeat_num)\n",
    "        self.D = Discriminator(self.image_size, self.d_conv_dim, self.c_dim, self.d_repeat_num)\n",
    "            \n",
    "        self.G.to(self.device)\n",
    "        self.D.to(self.device)\n",
    "    \n",
    "    def create_labels(self, c_org, c_dim=5, dataset='CelebA', selected_attrs=None):\n",
    "        \"\"\"Generate target domain labels for debugging and testing.\"\"\"\n",
    "        # Get hair color indices.\n",
    "        hair_color_indices = []\n",
    "        for i, attr_name in enumerate(selected_attrs):\n",
    "            if attr_name in ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']:\n",
    "                hair_color_indices.append(i)\n",
    "\n",
    "        c_trg_list = []\n",
    "        for i in range(c_dim):\n",
    "            c_trg = c_org.clone()\n",
    "            if i in hair_color_indices:  # Set one hair color to 1 and the rest to 0.\n",
    "                c_trg[:, i] = 1\n",
    "                for j in hair_color_indices:\n",
    "                    if j != i:\n",
    "                        c_trg[:, j] = 0\n",
    "            else:\n",
    "                c_trg[:, i] = (c_trg[:, i] == 0)  # Reverse attribute value.\n",
    "\n",
    "            c_trg_list.append(c_trg.to(self.device))\n",
    "        return c_trg_list\n",
    "    \n",
    "    \n",
    "    def restore_model(self, resume_iters):\n",
    "        \"\"\"Restore the trained generator and discriminator.\"\"\"\n",
    "        print('Loading the trained models from step {}...'.format(resume_iters))\n",
    "        G_path = os.path.join(self.model_save_dir, '{}-G.ckpt'.format(resume_iters))\n",
    "        D_path = os.path.join(self.model_save_dir, '{}-D.ckpt'.format(resume_iters))\n",
    "        self.G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n",
    "        self.D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))\n",
    "    \n",
    "    def print_network(self, model, name):\n",
    "        \"\"\"Print out the network information.\"\"\"\n",
    "        num_params = 0\n",
    "        for p in model.parameters():\n",
    "            num_params += p.numel()\n",
    "        print(model)\n",
    "        print(name)\n",
    "        print(\"The number of parameters: {}\".format(num_params))\n",
    "    \n",
    "    def denorm(self, x):\n",
    "        \"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp_(0, 1)\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"Translate images using StarGAN trained on a single dataset.\"\"\"\n",
    "        # Load the trained generator.\n",
    "        self.restore_model(self.test_iters)\n",
    "\n",
    "        # Set data loader.\n",
    "        data_loader = self.celeba_loader\n",
    "        with torch.no_grad():\n",
    "            for i, (x_real, c_org) in enumerate(data_loader):\n",
    "\n",
    "                # Prepare input images and target domain labels.\n",
    "                x_real = x_real.to(self.device)\n",
    "                c_trg_list = self.create_labels(c_org, self.c_dim, None, self.selected_attrs)\n",
    "\n",
    "                # Translate images.\n",
    "                \n",
    "                x_fake_list = [x_real]\n",
    "                for c_trg in c_trg_list:\n",
    "                    x_fake_list.append(self.G(x_real, c_trg))\n",
    "                \n",
    "                # Save the translated images.\n",
    "                x_concat = torch.cat(x_fake_list, dim=3)\n",
    "                result_path = os.path.join(self.result_dir, '{}-images.jpg'.format(i+1))\n",
    "                save_image(self.denorm(x_concat.data.cpu()), result_path, nrow=1, padding=0)\n",
    "                print('Saved real and fake images into {}...'.format(result_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver(celeba_loader)\n",
    "start = time.time()\n",
    "solver.test()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 (4 points)\n",
    "# Modify test_half_precision to use half precision (FP16) instead of full precision (FP32) weights and activations.\n",
    "# To use half precision both model and input has to be represented with half precision float values.\n",
    "# More information can be found in documentation: https://pytorch.org/docs/master/tensors.html\n",
    "# Solver.denorm() requires FP32 values so type of final results has to changed back.\n",
    "class SolverHP(Solver):       \n",
    "    def test_half_precision(self):\n",
    "        \"\"\"Translate images using StarGAN trained on a single dataset.\"\"\"\n",
    "        # Load the trained generator.\n",
    "        self.restore_model(self.test_iters)\n",
    "        self.G = self.G.half()\n",
    "        self.D = self.D.half()\n",
    "        # Set data loader.\n",
    "        data_loader = self.celeba_loader\n",
    "        with torch.no_grad():\n",
    "            for i, (x_real, c_org) in enumerate(data_loader):\n",
    "\n",
    "                # Prepare input images and target domain labels.\n",
    "                x_real = x_real.to(self.device).to(torch.half)\n",
    "                c_org = c_org.to(torch.half)\n",
    "                c_trg_list = self.create_labels(c_org, self.c_dim, None, self.selected_attrs)\n",
    "\n",
    "                # Translate images.\n",
    "                x_fake_list = [x_real]\n",
    "                for c_trg in c_trg_list:\n",
    "                    x_fake_list.append(self.G(x_real, c_trg))\n",
    "                \n",
    "                # Save the translated images.\n",
    "                x_concat = torch.cat(x_fake_list, dim=3)\n",
    "                result_path = os.path.join(self.result_dir, '{}-images.jpg'.format(i+1))\n",
    "                save_image(self.denorm(x_concat.data.cpu().to(torch.float32)), result_path, nrow=1, padding=0)\n",
    "                print('Saved real and fake images into {}...'.format(result_path))\n",
    "            \n",
    "solverHP = SolverHP(celeba_loader)\n",
    "solverHP.result_dir = 'stargan_celeba_128/resultsHP'\n",
    "start = time.time()\n",
    "solverHP.test_half_precision()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 (1 point)\n",
    "# Compare visual result. Compute average and maximum absolute difference between RGB values of results\n",
    "# generated with full precision and half precision representations.\n",
    "from PIL import Image\n",
    "id_of_example = 1\n",
    "im = Image.open(os.path.join(solver.result_dir, '{}-images.jpg'.format(id_of_example)))\n",
    "im_hp = Image.open(os.path.join(solverHP.result_dir, '{}-images.jpg'.format(id_of_example)))\n",
    "im_numpy = np.array(im).astype(np.float)\n",
    "im_numpy_hp = np.array(im_hp).astype(np.float)\n",
    "im_diff = im_numpy - im_numpy_hp\n",
    "average_difference = np.mean(im_diff)\n",
    "maximum_difference = np.max(im_diff)\n",
    "print('Average difference:', average_difference)\n",
    "print('Maximum difference:', maximum_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 (3 points)\n",
    "# Check total CPU and CUDA time and memory requirements of Generator\n",
    "# module with torchprof library: https://github.com/awwong1/torchprof\n",
    "import torchprof\n",
    "solver = Solver(celeba_loader)\n",
    "model = solver.G\n",
    "input1 = torch.randn(16, 3, 128, 128).cuda()\n",
    "input2 = torch.randn(16,5).cuda()\n",
    "\n",
    "with torchprof.Profile(model, use_cuda=True, profile_memory=True) as prof:\n",
    "    start = time.time()\n",
    "    model(input1, input2)   \n",
    "    print(f\"Time: {time.time() - start}\")  \n",
    "print(prof.display(show_events=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 (2 points)\n",
    "# Modify code to profile Generator module working in half precision mode.\n",
    "# Compare with full precision model results.\n",
    "solver = SolverHP(celeba_loader)\n",
    "model = solver.G.half()\n",
    "input1 = torch.randn(16, 3, 128, 128).cuda().to(torch.half)\n",
    "input2 = torch.randn(16,5).cuda().to(torch.half)\n",
    "with torchprof.Profile(model, use_cuda=True, profile_memory=True) as prof:\n",
    "    start = time.time()\n",
    "    model(input1, input2)   \n",
    "    print(f\"Time: {time.time() - start}\")\n",
    "print(prof.display(show_events=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab6-py3.7",
   "language": "python",
   "name": "lab6-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
