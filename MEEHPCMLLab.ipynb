{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wh# High Performance Machine Learning lab\n",
    "StarGAN for image-to-image translation in TensorFlow 2.3 Estimator API.\n",
    "\n",
    "## Author: Paweł Rościszewski\n",
    "  based on the [StarGAN Estimator example](https://github.com/tensorflow/gan/tree/master/tensorflow_gan/examples/stargan_estimator) by Wesley Qian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "import tensorflow_gan as tfgan\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_gan.examples.stargan import network\n",
    "\n",
    "from tensorflow_gan.examples.cyclegan import data_provider as cyclegan_dp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "logger = tf.get_logger()\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  # The number of images in each batch.\n",
    "patch_size = 128  # The patch size of images.\n",
    "\n",
    "generator_lr = 1e-4  # The generator learning rate.\n",
    "discriminator_lr = 1e-4  # The discriminator learning rate.\n",
    "max_number_of_steps = 1000000  # The maximum number of gradient steps.\n",
    "steps_per_eval = 1  # The number of steps after which evaluate the model.\n",
    "adam_beta1 = 0.5  # Adam Beta 1 for the Adam optimizer.\n",
    "adam_beta2 = 0.999  # Adam Beta 2 for the Adam optimizer.\n",
    "gen_disc_step_ratio = 0.2  # Generator:Discriminator training step ratio.\n",
    "\n",
    "override_generator_fn=None\n",
    "override_discriminator_fn=None\n",
    "\n",
    "master = ''  # Name of the TensorFlow master to use.\n",
    "ps_tasks = 0  # The number of parameter servers. If the value is 0, then the parameters are handled locally by the worker.\n",
    "task = 0  # The Task ID. This value is used when training with multiple workers to identify each worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HParams = collections.namedtuple('HParams', [\n",
    "    'batch_size', 'patch_size', 'generator_lr',\n",
    "    'discriminator_lr', 'max_number_of_steps', 'steps_per_eval', 'adam_beta1',\n",
    "    'adam_beta2', 'gen_disc_step_ratio', 'master', 'ps_tasks', 'task'\n",
    "])\n",
    "hparams = HParams(batch_size, patch_size, generator_lr, discriminator_lr, max_number_of_steps, \n",
    "                  steps_per_eval, adam_beta1, adam_beta2, gen_disc_step_ratio, master, ps_tasks, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_dataset(split, batch_size, patch_size, num_parallel_calls=None,\n",
    "                    shuffle=True, domains=None):\n",
    "    \"\"\"Provides batches of CelebA image patches.\n",
    "\n",
    "    Args:\n",
    "      split: Either 'train' or 'test'.\n",
    "      batch_size: The number of images in each batch.\n",
    "      patch_size: Python int. The patch size to extract.\n",
    "      num_parallel_calls: Number of threads dedicated to parsing.\n",
    "      shuffle: Whether to shuffle.\n",
    "      domains: Name of domains to transform between. Must be in Celeb A dataset.\n",
    "\n",
    "    Returns:\n",
    "      A tf.data.Dataset with:\n",
    "        * images:  `Tensor` of size [batch_size, 32, 32, 3] and type tf.float32.\n",
    "            Output pixel values are in [-1, 1].\n",
    "        * labels: A `Tensor` of size [batch_size, 10] of one-hot label\n",
    "            encodings with type tf.int32, or a `Tensor` of size [batch_size],\n",
    "            depending on the value of `one_hot`.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If `split` isn't `train` or `test`.\n",
    "    \"\"\"\n",
    "    ds = tfds.load('celeb_a:2.*.*', split=split, shuffle_files=shuffle, download=False,\n",
    "                   data_dir='/ssd_local/hpml/tensorflow_datasets/')\n",
    "    \n",
    "    def _filter_pred(attribute):\n",
    "        def _filter(element):\n",
    "            return element['attributes'][attribute]\n",
    "\n",
    "        return _filter\n",
    "\n",
    "    dss = tuple([ds.filter(_filter_pred(attribute)) for attribute in domains])\n",
    "    ds = tf.data.Dataset.zip(dss)\n",
    "\n",
    "    def _preprocess(*elements):\n",
    "        \"\"\"Map elements to the example dicts expected by the model.\"\"\"\n",
    "        output_dict = {}\n",
    "        num_domains = len(elements)\n",
    "        for idx, (domain, elem) in enumerate(zip(domains, elements)):\n",
    "            uint8_img = elem['image']\n",
    "            patch = cyclegan_dp.full_image_to_patch(uint8_img, patch_size)\n",
    "            label = tf.one_hot(idx, num_domains)\n",
    "            output_dict[domain] = {'images': patch, 'labels': label}\n",
    "        return output_dict\n",
    "\n",
    "    ds = (ds\n",
    "          .map(_preprocess, num_parallel_calls=num_parallel_calls)\n",
    "          .cache()\n",
    "          .repeat())\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    ds = (ds\n",
    "          .batch(batch_size, drop_remainder=True)\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_data(split, batch_size, patch_size, num_parallel_calls=None,\n",
    "                 shuffle=True, domains=None):\n",
    "    \"\"\"Provides batches of CelebA image patches.\n",
    "\n",
    "    Args:\n",
    "      split: Either 'train' or 'test'.\n",
    "      batch_size: The number of images in each batch.\n",
    "      patch_size: Python int. The patch size to extract.\n",
    "      num_parallel_calls: Number of threads dedicated to parsing.\n",
    "      shuffle: Whether to shuffle.\n",
    "      domains: Name of domains to transform between. Must be in Celeb A dataset.\n",
    "\n",
    "    Returns:\n",
    "      A tf.data.Dataset with:\n",
    "        * images:  `Tensor` of size [batch_size, patch_size, patch_size, 3] and\n",
    "            type tf.float32. Output pixel values are in [-1, 1].\n",
    "        * labels: A `Tensor` of size [batch_size, 10] of one-hot label\n",
    "            encodings with type tf.int32, or a `Tensor` of size [batch_size],\n",
    "            depending on the value of `one_hot`.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If `split` isn't `train` or `test`.\n",
    "    \"\"\"\n",
    "    ds = provide_dataset(split, batch_size, patch_size, num_parallel_calls,\n",
    "                         shuffle, domains)\n",
    "\n",
    "    next_batch = tf.data.make_one_shot_iterator(ds).get_next()\n",
    "    domains = next_batch.keys()\n",
    "    images = [next_batch[domain]['images'] for domain in domains]\n",
    "    labels = [next_batch[domain]['labels'] for domain in domains]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_optimizer(gen_lr, dis_lr, beta1, beta2):\n",
    "    \"\"\"Returns generator optimizer and discriminator optimizer.\n",
    "\n",
    "    Args:\n",
    "      gen_lr: A scalar float `Tensor` or a Python number.  The Generator learning\n",
    "        rate.\n",
    "      dis_lr: A scalar float `Tensor` or a Python number.  The Discriminator\n",
    "        learning rate.\n",
    "      beta1: A scalar float `Tensor` or a Python number. The beta1 parameter to\n",
    "        the `AdamOptimizer`.\n",
    "      beta2: A scalar float `Tensor` or a Python number. The beta2 parameter to\n",
    "        the `AdamOptimizer`.\n",
    "\n",
    "    Returns:\n",
    "      A tuple of generator optimizer and discriminator optimizer.\n",
    "    \"\"\"\n",
    "    gen_opt = tf.train.AdamOptimizer(\n",
    "        gen_lr, beta1=beta1, beta2=beta2, use_locking=True)\n",
    "    dis_opt = tf.train.AdamOptimizer(\n",
    "        dis_lr, beta1=beta1, beta2=beta2, use_locking=True)\n",
    "    return gen_opt, dis_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _define_train_step(gen_disc_step_ratio):\n",
    "    \"\"\"Get the training step for generator and discriminator for each GAN step.\n",
    "\n",
    "    Args:\n",
    "      gen_disc_step_ratio: A python number. The ratio of generator to\n",
    "        discriminator training steps.\n",
    "\n",
    "    Returns:\n",
    "      GANTrainSteps namedtuple representing the training step configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    if gen_disc_step_ratio <= 1:\n",
    "        discriminator_step = int(1 / gen_disc_step_ratio)\n",
    "        return tfgan.GANTrainSteps(1, discriminator_step)\n",
    "    else:\n",
    "        generator_step = int(gen_disc_step_ratio)\n",
    "        return tfgan.GANTrainSteps(generator_step, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_summary_image(estimator, test_images_np):\n",
    "    \"\"\"Returns a numpy image of the generate on the test images.\"\"\"\n",
    "    num_domains = len(test_images_np)\n",
    "\n",
    "    img_rows = []\n",
    "    for img_np in test_images_np:\n",
    "        def test_input_fn():\n",
    "            dataset_imgs = [img_np] * num_domains  # pylint:disable=cell-var-from-loop\n",
    "            dataset_lbls = [tf.one_hot([d], num_domains) for d in xrange(num_domains)]\n",
    "\n",
    "            # Make into a dataset.\n",
    "            dataset_imgs = np.stack(dataset_imgs)\n",
    "            dataset_imgs = np.expand_dims(dataset_imgs, 1)\n",
    "            dataset_lbls = tf.stack(dataset_lbls)\n",
    "            unused_tensor = tf.zeros(num_domains)\n",
    "            return tf.data.Dataset.from_tensor_slices(((dataset_imgs, dataset_lbls),\n",
    "                                                       unused_tensor))\n",
    "\n",
    "        prediction_iterable = estimator.predict(test_input_fn)\n",
    "        predictions = [next(prediction_iterable) for _ in xrange(num_domains)]\n",
    "        transform_row = np.concatenate([img_np] + predictions, 1)\n",
    "        img_rows.append(transform_row)\n",
    "\n",
    "    all_rows = np.concatenate(img_rows, 0)\n",
    "    # Normalize` [-1, 1] to [0, 1].\n",
    "    normalized_summary = (all_rows + 1.0) / 2.0\n",
    "    return normalized_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1 \n",
    "\n",
    "### DOWNLOAD 3 IMAGES OF PEOPLES FACES\n",
    "!wget <image_url> -O test_image1.jpg\n",
    "!wget <image_url> -O test_image2.jpg\n",
    "!wget <image_url> -O test_image3.jpg\n",
    "\n",
    "### CONVERT THEM TO 128x128 PNG\n",
    "!convert test_image1.jpg -resize 128x128 test_image1.png\n",
    "!convert test_image2.jpg -resize 128x128 test_image2.png\n",
    "!convert test_image3.jpg -resize 128x128 test_image3.png\n",
    "\n",
    "### Verify the images are in PNG format\n",
    "!file test_image1.png\n",
    "!file test_image2.png\n",
    "!file test_image3.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make sure steps integers are consistent.\n",
    "if hparams.max_number_of_steps % hparams.steps_per_eval != 0:\n",
    "    raise ValueError('`max_number_of_steps` must be divisible by '\n",
    "                     '`steps_per_eval`.')\n",
    "\n",
    "# Create optimizers.\n",
    "gen_opt, dis_opt = _get_optimizer(hparams.generator_lr,\n",
    "                                  hparams.discriminator_lr,\n",
    "                                  hparams.adam_beta1, hparams.adam_beta2)\n",
    "### TASK 2 - CONFIGURE CONFIG PROTO\n",
    "config_proto = tf.ConfigProto()\n",
    "config_proto.gpu_options.allow_growth = True\n",
    "run_config = tf.estimator.RunConfig(session_config=config_proto) \n",
    "### TASK 2\n",
    "\n",
    "\n",
    "# Create estimator.\n",
    "stargan_estimator = tfgan.estimator.StarGANEstimator(\n",
    "    model_dir='models',\n",
    "    generator_fn=override_generator_fn or network.generator,\n",
    "    discriminator_fn=override_discriminator_fn or network.discriminator,\n",
    "    loss_fn=tfgan.stargan_loss,\n",
    "    generator_optimizer=gen_opt,\n",
    "    discriminator_optimizer=dis_opt,\n",
    "    get_hooks_fn=tfgan.get_sequential_train_hooks(\n",
    "        _define_train_step(hparams.gen_disc_step_ratio)),\n",
    "    add_summaries=tfgan.estimator.SummaryType.IMAGES\n",
    "    #,config=run_config # UNCOMMENT FOR TASK 2\n",
    ")\n",
    "\n",
    "# Get input function for training and test images.\n",
    "train_input_fn = lambda: provide_data(  # pylint:disable=g-long-lambda\n",
    "    'train', hparams.batch_size, hparams.patch_size,\n",
    "    ### TASK 1 - SELECT YOUR DOMAINS FROM:\n",
    "    ### LINK: https://www.tensorflow.org/datasets/catalog/celeb_a\n",
    "    domains=('domain1', 'domain2', 'domain3'))\n",
    "\n",
    "test_images_np = np.array([cv2.imread('test_image1.png') / 255.0 * 2 - 1,\n",
    "                          cv2.imread('test_image2.png') / 255.0 * 2 - 1,\n",
    "                          cv2.imread('test_image3.png') / 255.0 * 2 - 1],\n",
    "                          dtype=np.float32)\n",
    "test_images_np = test_images_np[:,:,:,::-1]\n",
    "print(test_images_np.shape)\n",
    "\n",
    "# Periodically train and visualize predictions\n",
    "cur_step = 0\n",
    "while cur_step < hparams.max_number_of_steps:\n",
    "    cur_step += hparams.steps_per_eval\n",
    "    stargan_estimator.train(train_input_fn, steps=cur_step)\n",
    "    summary_img = _get_summary_image(stargan_estimator, test_images_np)\n",
    "    plt.imshow(summary_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
