{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Performance Machine Learning lab\n",
    "StarGAN for image-to-image translation in TensorFlow 2.3 Estimator API.\n",
    "\n",
    "## Author: Paweł Rościszewski\n",
    "  based on the [StarGAN Estimator example](https://github.com/tensorflow/gan/tree/master/tensorflow_gan/examples/stargan_estimator) by Wesley Qian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow               2.3.2\n",
      "tensorflow-datasets      4.2.0\n",
      "tensorflow-estimator     2.3.0\n",
      "tensorflow-gan           2.0.0\n",
      "tensorflow-hub           0.12.0\n",
      "tensorflow-metadata      0.30.0\n",
      "tensorflow-probability   0.11.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/macierz/home/s165452/hpmllab/venv/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !python --version\n",
    "!pip list | grep tensorflow\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "\n",
    "import tensorflow_gan as tfgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_gan.examples.stargan import network\n",
    "\n",
    "from tensorflow_gan.examples.cyclegan import data_provider as cyclegan_dp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4  # The number of images in each batch.\n",
    "patch_size = 128  # The patch size of images.\n",
    "\n",
    "generator_lr = 1e-4  # The generator learning rate.\n",
    "discriminator_lr = 1e-4  # The discriminator learning rate.\n",
    "max_number_of_steps = 1000000  # The maximum number of gradient steps.\n",
    "steps_per_eval = 1  # The number of steps after which evaluate the model.\n",
    "adam_beta1 = 0.5  # Adam Beta 1 for the Adam optimizer.\n",
    "adam_beta2 = 0.999  # Adam Beta 2 for the Adam optimizer.\n",
    "gen_disc_step_ratio = 0.2  # Generator:Discriminator training step ratio.\n",
    "\n",
    "override_generator_fn=None\n",
    "override_discriminator_fn=None\n",
    "\n",
    "master = ''  # Name of the TensorFlow master to use.\n",
    "ps_tasks = 0  # The number of parameter servers. If the value is 0, then the parameters are handled locally by the worker.\n",
    "task = 0  # The Task ID. This value is used when training with multiple workers to identify each worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HParams = collections.namedtuple('HParams', [\n",
    "    'batch_size', 'patch_size', 'generator_lr',\n",
    "    'discriminator_lr', 'max_number_of_steps', 'steps_per_eval', 'adam_beta1',\n",
    "    'adam_beta2', 'gen_disc_step_ratio', 'master', 'ps_tasks', 'task'\n",
    "])\n",
    "hparams = HParams(batch_size, patch_size, generator_lr, discriminator_lr, max_number_of_steps, \n",
    "                  steps_per_eval, adam_beta1, adam_beta2, gen_disc_step_ratio, master, ps_tasks, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_dataset(split, batch_size, patch_size, num_parallel_calls=None,\n",
    "                    shuffle=True, domains=None):\n",
    "    \"\"\"Provides batches of CelebA image patches.\n",
    "\n",
    "    Args:\n",
    "      split: Either 'train' or 'test'.\n",
    "      batch_size: The number of images in each batch.\n",
    "      patch_size: Python int. The patch size to extract.\n",
    "      num_parallel_calls: Number of threads dedicated to parsing.\n",
    "      shuffle: Whether to shuffle.\n",
    "      domains: Name of domains to transform between. Must be in Celeb A dataset.\n",
    "\n",
    "    Returns:\n",
    "      A tf.data.Dataset with:\n",
    "        * images:  `Tensor` of size [batch_size, 32, 32, 3] and type tf.float32.\n",
    "            Output pixel values are in [-1, 1].\n",
    "        * labels: A `Tensor` of size [batch_size, 10] of one-hot label\n",
    "            encodings with type tf.int32, or a `Tensor` of size [batch_size],\n",
    "            depending on the value of `one_hot`.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If `split` isn't `train` or `test`.\n",
    "    \"\"\"\n",
    "    ds = tfds.load('celeb_a:2.*.*', split=split, shuffle_files=shuffle, download=False,\n",
    "                   data_dir='/ssd_local/hpml/tensorflow_datasets/')\n",
    "\n",
    "    def _filter_pred(attribute):\n",
    "        def _filter(element):\n",
    "            return element['attributes'][attribute]\n",
    "\n",
    "        return _filter\n",
    "\n",
    "    dss = tuple([ds.filter(_filter_pred(attribute)) for attribute in domains])\n",
    "    ds = tf.data.Dataset.zip(dss)\n",
    "\n",
    "    def _preprocess(*elements):\n",
    "        \"\"\"Map elements to the example dicts expected by the model.\"\"\"\n",
    "        output_dict = {}\n",
    "        num_domains = len(elements)\n",
    "        for idx, (domain, elem) in enumerate(zip(domains, elements)):\n",
    "            uint8_img = elem['image']\n",
    "            patch = cyclegan_dp.full_image_to_patch(uint8_img, patch_size)\n",
    "            label = tf.one_hot(idx, num_domains)\n",
    "            output_dict[domain] = {'images': patch, 'labels': label}\n",
    "        return output_dict\n",
    "\n",
    "    ds = (ds\n",
    "          .map(_preprocess, num_parallel_calls=num_parallel_calls)\n",
    "          .cache()\n",
    "          .repeat())\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    ds = (ds\n",
    "          .batch(batch_size, drop_remainder=True)\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = provide_dataset(\n",
    "#     'train', hparams.batch_size, hparams.patch_size,\n",
    "#     domains=('Narrow_Eyes', 'Oval_Face', 'Goatee'))\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = ds\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_data(split, batch_size, patch_size, num_parallel_calls=None,\n",
    "                 shuffle=True, domains=None):\n",
    "    \"\"\"Provides batches of CelebA image patches.\n",
    "\n",
    "    Args:\n",
    "      split: Either 'train' or 'test'.\n",
    "      batch_size: The number of images in each batch.\n",
    "      patch_size: Python int. The patch size to extract.\n",
    "      num_parallel_calls: Number of threads dedicated to parsing.\n",
    "      shuffle: Whether to shuffle.\n",
    "      domains: Name of domains to transform between. Must be in Celeb A dataset.\n",
    "\n",
    "    Returns:\n",
    "      A tf.data.Dataset with:\n",
    "        * images:  `Tensor` of size [batch_size, patch_size, patch_size, 3] and\n",
    "            type tf.float32. Output pixel values are in [-1, 1].\n",
    "        * labels: A `Tensor` of size [batch_size, 10] of one-hot label\n",
    "            encodings with type tf.int32, or a `Tensor` of size [batch_size],\n",
    "            depending on the value of `one_hot`.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If `split` isn't `train` or `test`.\n",
    "    \"\"\"\n",
    "    ds = provide_dataset(split, batch_size, patch_size, num_parallel_calls,\n",
    "                         shuffle, domains)\n",
    "\n",
    "    next_batch = tf.data.make_one_shot_iterator(ds).get_next()\n",
    "    domains = next_batch.keys()\n",
    "    images = [next_batch[domain]['images'] for domain in domains]\n",
    "    labels = [next_batch[domain]['labels'] for domain in domains]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_tfdata(split, batch_size, patch_size, num_parallel_calls=None, shuffle=True, domains=None):\n",
    "\n",
    "    ds = provide_dataset(split, batch_size, patch_size, num_parallel_calls,\n",
    "                         shuffle, domains)\n",
    "\n",
    "    next_batch = tf.data.make_one_shot_iterator(ds).get_next()\n",
    "    domains = next_batch.keys()\n",
    "    images = [next_batch[domain]['images'] for domain in domains]\n",
    "    labels = [next_batch[domain]['labels'] for domain in domains]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_dataset_batch(split, batch_size, patch_size, num_parallel_calls=None,\n",
    "                    shuffle=True, domains=None) -> tf.Tensor:\n",
    "    ds = tfds.load('celeb_a:2.*.*', split=split, shuffle_files=shuffle, download=False,\n",
    "                   data_dir='/ssd_local/hpml/tensorflow_datasets/')\n",
    "\n",
    "    def _filter_pred(attribute):\n",
    "        def _filter(element):\n",
    "            return element['attributes'][attribute]\n",
    "\n",
    "        return _filter\n",
    "\n",
    "    dss = tuple([ds.filter(_filter_pred(attribute)) for attribute in domains])\n",
    "    ds = tf.data.Dataset.zip(dss)\n",
    "\n",
    "    def _preprocess(*elements):\n",
    "        \"\"\"Map elements to the example dicts expected by the model.\"\"\"\n",
    "        output_dict = {}\n",
    "        num_domains = len(elements)\n",
    "        for idx, (domain, elem) in enumerate(zip(domains, elements)):\n",
    "            uint8_img = elem['image']\n",
    "            patch = cyclegan_dp.full_image_to_patch(uint8_img, patch_size)\n",
    "            label = tf.one_hot(idx, num_domains)\n",
    "            output_dict[domain] = {'images': patch, 'labels': label}\n",
    "        return output_dict\n",
    "\n",
    "    ds = (ds\n",
    "          .map(_preprocess, num_parallel_calls=num_parallel_calls)\n",
    "          .cache()\n",
    "          .repeat())\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    ds = (ds\n",
    "          .batch(batch_size, drop_remainder=True)\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "#     next_batch: tf.Tensor = tf.data.make_one_shot_iterator(ds)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
    "#               {\"a\": 2, \"b\": \"bar\"},\n",
    "#               {\"a\": 3, \"b\": \"baz\"}])\n",
    "# dataset = tf.data.Dataset.from_generator(lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
    "# # `map_func` takes a single argument of type `dict` with the same keys\n",
    "# # as the elements.\n",
    "# # result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
    "# dataset.\n",
    "# dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "# for element in dataset:\n",
    "#     print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # images, labels = provide_data('train', hparams.batch_size, hparams.patch_size, domains=('Narrow_Eyes', 'Oval_Face', 'Goatee'))\n",
    "# ds = provide_tfdata('train', hparams.batch_size, hparams.patch_size, domains=('Narrow_Eyes', 'Oval_Face', 'Goatee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.executing_eagerly()\n",
    "# images, labels = provide_data('train', hparams.batch_size, hparams.patch_size, domains=('Narrow_Eyes', 'Oval_Face', 'Goatee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = provide_tfdata('train', hparams.batch_size, hparams.patch_size, domains=('Narrow_Eyes', 'Oval_Face', 'Goatee'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_optimizer(gen_lr, dis_lr, beta1, beta2):\n",
    "    \"\"\"Returns generator optimizer and discriminator optimizer.\n",
    "\n",
    "    Args:\n",
    "      gen_lr: A scalar float `Tensor` or a Python number.  The Generator learning\n",
    "        rate.\n",
    "      dis_lr: A scalar float `Tensor` or a Python number.  The Discriminator\n",
    "        learning rate.\n",
    "      beta1: A scalar float `Tensor` or a Python number. The beta1 parameter to\n",
    "        the `AdamOptimizer`.\n",
    "      beta2: A scalar float `Tensor` or a Python number. The beta2 parameter to\n",
    "        the `AdamOptimizer`.\n",
    "\n",
    "    Returns:\n",
    "      A tuple of generator optimizer and discriminator optimizer.\n",
    "    \"\"\"\n",
    "    gen_opt = tf.train.AdamOptimizer(\n",
    "        gen_lr, beta1=beta1, beta2=beta2, use_locking=True)\n",
    "    dis_opt = tf.train.AdamOptimizer(\n",
    "        dis_lr, beta1=beta1, beta2=beta2, use_locking=True)\n",
    "    return gen_opt, dis_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _define_train_step(gen_disc_step_ratio):\n",
    "    \"\"\"Get the training step for generator and discriminator for each GAN step.\n",
    "\n",
    "    Args:\n",
    "      gen_disc_step_ratio: A python number. The ratio of generator to\n",
    "        discriminator training steps.\n",
    "\n",
    "    Returns:\n",
    "      GANTrainSteps namedtuple representing the training step configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    if gen_disc_step_ratio <= 1:\n",
    "        discriminator_step = int(1 / gen_disc_step_ratio)\n",
    "        return tfgan.GANTrainSteps(1, discriminator_step)\n",
    "    else:\n",
    "        generator_step = int(gen_disc_step_ratio)\n",
    "        return tfgan.GANTrainSteps(generator_step, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_summary_image(estimator, test_images_np):\n",
    "    \"\"\"Returns a numpy image of the generate on the test images.\"\"\"\n",
    "    num_domains = len(test_images_np)\n",
    "\n",
    "    img_rows = []\n",
    "    for img_np in test_images_np:\n",
    "        def test_input_fn():\n",
    "            dataset_imgs = [img_np] * num_domains  # pylint:disable=cell-var-from-loop\n",
    "            dataset_lbls = [tf.one_hot([d], num_domains) for d in xrange(num_domains)]\n",
    "\n",
    "            # Make into a dataset.\n",
    "            dataset_imgs = np.stack(dataset_imgs)\n",
    "            dataset_imgs = np.expand_dims(dataset_imgs, 1)\n",
    "            dataset_lbls = tf.stack(dataset_lbls)\n",
    "            unused_tensor = tf.zeros(num_domains)\n",
    "            return tf.data.Dataset.from_tensor_slices(((dataset_imgs, dataset_lbls),\n",
    "                                                       unused_tensor))\n",
    "\n",
    "        prediction_iterable = estimator.predict(test_input_fn)\n",
    "        predictions = [next(prediction_iterable) for _ in xrange(num_domains)]\n",
    "        transform_row = np.concatenate([img_np] + predictions, 1)\n",
    "        img_rows.append(transform_row)\n",
    "\n",
    "    all_rows = np.concatenate(img_rows, 0)\n",
    "    # Normalize` [-1, 1] to [0, 1].\n",
    "    normalized_summary = (all_rows + 1.0) / 2.0\n",
    "    return normalized_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O test_image1.jpg https://static01.nyt.com/newsgraphics/2020/11/12/fake-people/4b806cf591a8a76adfc88d19e90c8c634345bf3d/fallbacks/mobile-03.jpg \n",
    "# !wget -O test_image2.jpg https://static01.nyt.com/newsgraphics/2020/11/12/fake-people/4b806cf591a8a76adfc88d19e90c8c634345bf3d/fallbacks/mobile-04.jpg\n",
    "# !wget -O test_image3.jpg https://static01.nyt.com/newsgraphics/2020/11/12/fake-people/4b806cf591a8a76adfc88d19e90c8c634345bf3d/fallbacks/mobile-05.jpg\n",
    "    \n",
    "# !convert test_image1.jpg -resize 128x128 test_image1.png\n",
    "# !convert test_image2.jpg -resize 128x128 test_image2.png\n",
    "# !convert test_image3.jpg -resize 128x128 test_image3.png\n",
    "\n",
    "# !file test_image1.png\n",
    "# !file test_image2.png\n",
    "# !file test_image3.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_device(dev_type):\n",
    "    for dev in device_lib.list_local_devices():\n",
    "        if dev.device_type == dev_type:\n",
    "            return dev\n",
    "        \n",
    "    print(\"No matching device found :(\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14539651827456077790\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5125796746441341751\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3168644697156639013\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5698663232\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1690321202961177756\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:chief/replica:0/task:0/device:CPU:0', '/job:chief/replica:0/task:0/device:XLA_CPU:0', '/job:chief/replica:0/task:0/device:XLA_GPU:0', '/job:chief/replica:0/task:0/device:GPU:0']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:chief/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}, task_type = 'chief', task_id = 0, num_workers = 2, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {'cluster': {'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}, 'task': {'type': 'chief', 'index': 0}}\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:RunConfig initialized for Distribute Coordinator with INDEPENDENT_WORKER mode\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategyV1 object at 0x7f1eb40c5150>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'independent_worker'}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function StarGANEstimator.__init__.<locals>._model_fn at 0x7f1eb8940d40>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Make sure steps integers are consistent.\n",
    "if hparams.max_number_of_steps % hparams.steps_per_eval != 0:\n",
    "    raise ValueError('`max_number_of_steps` must be divisible by '\n",
    "                     '`steps_per_eval`.')\n",
    "\n",
    "# Create optimizers.\n",
    "gen_opt, dis_opt = _get_optimizer(hparams.generator_lr,\n",
    "                                  hparams.discriminator_lr,\n",
    "                                  hparams.adam_beta1, hparams.adam_beta2)\n",
    "\n",
    "config_proto = tf.ConfigProto()\n",
    "config_proto.gpu_options.allow_growth = True\n",
    "config_proto.allow_soft_placement=True\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# dev_fn = lambda op: get_device(\"CPU\").name if get_device(\"CPU\") else None\n",
    "\n",
    "# dev_fn = lambda op: '/cpu:0'\n",
    "# run_config = tf.estimator.RunConfig(session_config=config_proto )#, device_fn=dev_fn)\n",
    "import json\n",
    "\n",
    "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
    "    \"cluster\": {\n",
    "        \"chief\": [\"172.20.83.213:23456\"],\n",
    "        \"worker\": [ \"172.20.83.210:23456\"],\n",
    "    },\n",
    "   \"task\": {\"type\": \"chief\", \"index\": 0}\n",
    "})\n",
    "\n",
    "import tensorflow\n",
    "strategy =  tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "run_config = tf.estimator.RunConfig(session_config=config_proto, train_distribute=strategy)\n",
    "# run_config = tf.estimator.RunConfig(session_config=config_proto)\n",
    "\n",
    "\n",
    "# Create estimator.\n",
    "stargan_estimator = tfgan.estimator.StarGANEstimator(\n",
    "#     model_dir='models',\n",
    "    model_dir='/tmp/models',\n",
    "    generator_fn=override_generator_fn or network.generator,\n",
    "    discriminator_fn=override_discriminator_fn or network.discriminator,\n",
    "    loss_fn=tfgan.stargan_loss,\n",
    "    generator_optimizer=gen_opt,\n",
    "    discriminator_optimizer=dis_opt,\n",
    "    get_hooks_fn=tfgan.get_sequential_train_hooks(\n",
    "        _define_train_step(hparams.gen_disc_step_ratio)),\n",
    "    add_summaries=tfgan.estimator.SummaryType.IMAGES,\n",
    "    config=run_config)\n",
    "\n",
    "# Get input function for training and test images.\n",
    "train_input_fn = lambda: provide_dataset_batch(\n",
    "    'train', hparams.batch_size, hparams.patch_size,\n",
    "    domains=('Narrow_Eyes', 'Oval_Face', 'Goatee'))\n",
    "\n",
    "test_images_np = np.array([cv2.imread('test_image1.png') / 255.0 * 2 - 1,\n",
    "                          cv2.imread('test_image2.png') / 255.0 * 2 - 1,\n",
    "                          cv2.imread('test_image3.png') / 255.0 * 2 - 1],\n",
    "                          dtype=np.float32)\n",
    "test_images_np = test_images_np[:,:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter_log(tensors):\n",
    "    summary_img = _get_summary_image(stargan_estimator, test_images_np)\n",
    "    plt.imshow(summary_img)\n",
    "    plt.show()\n",
    "    return f'Current Iteration: {tensors[\"total_iterations\"]}'\n",
    "\n",
    "\n",
    "import time\n",
    "class PerformanceMeasurementHook(tf.train.SessionRunHook):\n",
    "    def __init__(self, batch_size, every_steps=5):\n",
    "        self.every_steps = every_steps\n",
    "        self.counter = 0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def begin(self):\n",
    "        self.start = time.time()\n",
    "        \n",
    "    def after_run(self, run_context, run_values):\n",
    "        self.counter+=1\n",
    "        if (self.counter<self.every_steps):\n",
    "            return\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        self.counter=0\n",
    "        \n",
    "        diff = end - self.start\n",
    "        \n",
    "        avg_step = diff/self.every_steps\n",
    "        print(f\"PERFORMANCE METRICS: Average step execution time: {avg_step:.4f}s\")\n",
    "        \n",
    "        image_rate =  (self.every_steps * self.batch_size) / diff\n",
    "        print(f\"PERFORMANCE METRICS: Average image rate: {image_rate:.4f} img/s\")\n",
    "        self.start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.\n",
      "INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}, task_type = 'chief', task_id = 0, environment = None, rpc_layer = 'grpc'\n",
      "WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:chief/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}, task_type = 'chief', task_id = 0, num_workers = 2, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:chief/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}, task_type = 'chief', task_id = 0, num_workers = 2, local_devices = ('/job:chief/task:0/device:GPU:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:Updated config: {'_model_dir': '/tmp/models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategyV1 object at 0x7f1eb8b9f350>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'chief': ['172.20.83.213:23456'], 'worker': ['172.20.83.210:23456']}), '_task_type': 'chief', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://172.20.83.213:23456', '_evaluation_master': 'grpc://172.20.83.213:23456', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'independent_worker'}\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:339: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/examples/stargan/layers.py:40: conv2d (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/examples/stargan/layers.py:51: conv2d_transpose (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/examples/stargan/network.py:96: flatten (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/examples/stargan/layers.py:392: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/python/eval/summaries.py:261: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "INFO:tensorflow:Collective batch_all_reduce: 50 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_gan/python/contrib_utils.py:56: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Collective batch_all_reduce: 8 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_devices = 1, group_size = 2, communication_hint = AUTO, num_packs = 1\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f1eb891ee60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f1eb891ee60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Collective ops may deadlock with `save_checkpoints_secs` please use `save_checkpoint_steps` instead. Clearing `save_checkpoint_secs` and setting `save_checkpoint_steps` to 1000 now.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:all_hooks [<tensorflow_estimator.python.estimator.util.DistributedIteratorInitializerHook object at 0x7f1ebb77f190>, <tensorflow.python.training.basic_session_run_hooks.NanTensorHook object at 0x7f1ed0101850>, <tensorflow.python.training.basic_session_run_hooks.LoggingTensorHook object at 0x7f1e5443f250>, <tensorflow_gan.python.train.RunTrainOpsHook object at 0x7f1e54352b50>, <tensorflow_gan.python.train.RunTrainOpsHook object at 0x7f1e50270090>, <tensorflow.python.training.basic_session_run_hooks.StepCounterHook object at 0x7f1e5453e7d0>, <tensorflow.python.training.basic_session_run_hooks.SummarySaverHook object at 0x7f1eb8b9abd0>, <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f1e54444250>]\n",
      "INFO:tensorflow:Creating chief session creator with config: device_filters: \"/job:chief/task:0\"\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    scoped_allocator_optimization: ON\n",
      "    scoped_allocator_opts {\n",
      "      enable_op: \"CollectiveReduce\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental {\n",
      "  collective_group_leader: \"/job:chief/replica:0/task:0\"\n",
      "}\n",
      "\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the iterator's `initializer` property instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-0\n",
      "WARNING:tensorflow:From /macierz/home/s165452/hpmllab/venv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1077: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/models/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    }
   ],
   "source": [
    "logging_hook = tf.train.LoggingTensorHook({\"total_iterations\": \"global_step\"}, every_n_iter=hparams.steps_per_eval, formatter=formatter_log)       \n",
    "performace_hook = PerformanceMeasurementHook(batch_size=hparams.batch_size, every_steps=2)\n",
    "\n",
    "# profiler_hook = tf.estimator.ProfilerHook(save_steps=True, output_dir='./', show_dataflow=True, show_memory=True)\n",
    "# res = stargan_estimator.train(train_input_fn,hooks=[logging_hook, performace_hook, profiler_hook], max_steps=hparams.max_number_of_steps)\n",
    "\n",
    "\n",
    "tf.estimator.train_and_evaluate(stargan_estimator,\n",
    "                                train_spec=tf.estimator.TrainSpec(input_fn=train_input_fn),\n",
    "                                eval_spec=tf.estimator.EvalSpec(input_fn=train_input_fn))\n",
    "\n",
    "\n",
    "# res = stargan_estimator.train(train_input_fn, hooks=[logging_hook, performace_hook], max_steps=hparams.max_number_of_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),'b': [5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_input_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(tf.range(12), (3,4))\n",
    "\n",
    "p, q, r = tf.unstack(x)\n",
    "p.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
